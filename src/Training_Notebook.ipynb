{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f7dd87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from matplotlib.patches import Rectangle\n",
    "import cv2\n",
    "import yfinance as yf\n",
    "from datetime import datetime, timedelta\n",
    "from ultralytics import YOLO\n",
    "import random\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "import yaml\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "508eaec1",
   "metadata": {},
   "source": [
    "## 2. Preparing the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a098f8",
   "metadata": {},
   "source": [
    "### 2.1 Generating candlestick chart images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7b85417",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_candlestick_chart(ticker, period=\"2y\", interval=\"1d\", output_dir=\"charts\"):\n",
    "    \"\"\"\n",
    "    Generate candlestick chart images from financial data\n",
    "    \n",
    "    Args:\n",
    "        ticker (str): Stock ticker symbol\n",
    "        period (str): Data period (e.g., '2y' for 2 years)\n",
    "        interval (str): Data interval (e.g., '1d' for daily)\n",
    "        output_dir (str): Directory to save generated charts\n",
    "    \n",
    "    Returns:\n",
    "        str: Path to the saved chart image\n",
    "    \"\"\"\n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Fetch data using yfinance\n",
    "    data = yf.download(ticker, period=period, interval=interval)\n",
    "    \n",
    "    # Check if data is empty\n",
    "    if len(data) == 0:\n",
    "        print(f\"No data found for {ticker}\")\n",
    "        return None\n",
    "    \n",
    "    # Create figure and axis\n",
    "    fig, ax = plt.figure(figsize=(12, 8), dpi=100), plt.subplot(1, 1, 1)\n",
    "    \n",
    "    # Format date axis\n",
    "    ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))\n",
    "    \n",
    "    # Plot candlestick chart\n",
    "    width = 0.6\n",
    "    width2 = 0.05\n",
    "    \n",
    "    # Loop through data and plot each candlestick\n",
    "    for i, (idx, row) in enumerate(data.iterrows()):\n",
    "        # Calculate colors based on price movement\n",
    "        if row['Close'] >= row['Open']:\n",
    "            color = 'green'\n",
    "            body_height = row['Close'] - row['Open']\n",
    "        else:\n",
    "            color = 'red'\n",
    "            body_height = row['Open'] - row['Close']\n",
    "        \n",
    "        # Plot the candlestick body\n",
    "        rect = Rectangle(\n",
    "            xy=(i-width/2, min(row['Open'], row['Close'])),\n",
    "            width=width,\n",
    "            height=body_height,\n",
    "            facecolor=color,\n",
    "            edgecolor='black',\n",
    "            linewidth=0.5\n",
    "        )\n",
    "        ax.add_patch(rect)\n",
    "        \n",
    "        # Plot the upper and lower wicks\n",
    "        ax.plot([i, i], [row['Low'], min(row['Open'], row['Close'])], color='black', linewidth=0.5)\n",
    "        ax.plot([i, i], [max(row['Open'], row['Close']), row['High']], color='black', linewidth=0.5)\n",
    "    \n",
    "    # Set title and labels\n",
    "    ax.set_title(f\"{ticker} Candlestick Chart\", fontsize=12)\n",
    "    ax.set_xlabel(\"Date\", fontsize=10)\n",
    "    ax.set_ylabel(\"Price\", fontsize=10)\n",
    "    \n",
    "    # Adjust the x-axis to show the most recent time period\n",
    "    ax.set_xlim(-1, len(data) + 1)\n",
    "    \n",
    "    # Set y-axis limits with some padding\n",
    "    y_min = data['Low'].min() * 0.95\n",
    "    y_max = data['High'].max() * 1.05\n",
    "    ax.set_ylim(y_min, y_max)\n",
    "    \n",
    "    # Generate a unique filename\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    output_path = os.path.join(output_dir, f\"{ticker}_{timestamp}.jpg\")\n",
    "    \n",
    "    # Save the chart as an image\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_path)\n",
    "    plt.close(fig)\n",
    "    \n",
    "    return output_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6becdfd",
   "metadata": {},
   "source": [
    "### 2.2 Generating candlestick patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f890570e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_pattern_dataset(tickers, patterns, num_samples_per_pattern=100, output_dir=\"pattern_dataset\"):\n",
    "    \"\"\"\n",
    "    Generate a dataset of candlestick patterns\n",
    "    \n",
    "    Args:\n",
    "        tickers (list): List of stock ticker symbols\n",
    "        patterns (dict): Dictionary mapping pattern names to functions that check for patterns\n",
    "        num_samples_per_pattern (int): Number of samples to generate per pattern\n",
    "        output_dir (str): Directory to save the dataset\n",
    "    \n",
    "    Returns:\n",
    "        list: Paths to the generated chart images with pattern annotations\n",
    "    \"\"\"\n",
    "    # Create output directory\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Create pattern-specific directories\n",
    "    for pattern_name in patterns.keys():\n",
    "        os.makedirs(os.path.join(output_dir, pattern_name), exist_ok=True)\n",
    "    \n",
    "    generated_charts = []\n",
    "    \n",
    "    # Number of patterns detected per type\n",
    "    pattern_counts = {pattern_name: 0 for pattern_name in patterns.keys()}\n",
    "    \n",
    "    # Loop through tickers to get data\n",
    "    for ticker in tqdm(tickers, desc=\"Processing tickers\"):\n",
    "        try:\n",
    "            # Get longer period data to have enough patterns\n",
    "            data = yf.download(ticker, period=\"5y\", interval=\"1d\")\n",
    "            \n",
    "            if len(data) < 30:  # Skip if not enough data\n",
    "                continue\n",
    "                \n",
    "            print(f\"Downloaded {len(data)} days of data for {ticker}\")\n",
    "            \n",
    "            # Check for patterns in data\n",
    "            for pattern_name, pattern_func in patterns.items():\n",
    "                try:\n",
    "                    pattern_signals = pattern_func(data)\n",
    "                    \n",
    "                    # Convert to regular Python list of indices where patterns are found\n",
    "                    pattern_indices = []\n",
    "                    for i in range(len(pattern_signals)):\n",
    "                        if pattern_signals[i]:\n",
    "                            pattern_indices.append(i)\n",
    "                    \n",
    "                    pattern_count = len(pattern_indices)\n",
    "                    \n",
    "                    print(f\"Found {pattern_count} {pattern_name} patterns in {ticker}\")\n",
    "                    pattern_counts[pattern_name] += pattern_count\n",
    "                    \n",
    "                    # If patterns are found, generate images\n",
    "                    if pattern_count > 0:\n",
    "                        # Select random samples if there are more than needed\n",
    "                        samples_per_ticker = min(\n",
    "                            num_samples_per_pattern // len(tickers), \n",
    "                            len(pattern_indices)\n",
    "                        )\n",
    "                        samples_per_ticker = max(1, samples_per_ticker)  # Ensure at least 1 sample\n",
    "                        \n",
    "                        if len(pattern_indices) > samples_per_ticker:\n",
    "                            pattern_indices = np.random.choice(\n",
    "                                pattern_indices, \n",
    "                                size=samples_per_ticker, \n",
    "                                replace=False\n",
    "                            ).tolist()\n",
    "                        \n",
    "                        # Generate chart for each pattern instance\n",
    "                        for idx in pattern_indices:\n",
    "                            # Ensure we have enough data before and after the pattern\n",
    "                            if idx < 10 or idx >= len(data) - 6:\n",
    "                                continue\n",
    "                                \n",
    "                            # Extract data window (10 candles before, pattern, 5 candles after)\n",
    "                            window_data = data.iloc[idx-10:idx+6]\n",
    "                            \n",
    "                            # Create figure and axis with a specific figure number to avoid warnings\n",
    "                            fig_num = len(generated_charts) % 20  # Reuse figure numbers to avoid too many open figures\n",
    "                            plt.close(fig_num)  # Close if previously opened\n",
    "                            fig = plt.figure(num=fig_num, figsize=(12, 8), dpi=100)\n",
    "                            ax = fig.add_subplot(1, 1, 1)\n",
    "                            \n",
    "                            # Plot candlestick chart for the window\n",
    "                            width = 0.6\n",
    "                            \n",
    "                            # Loop through window data and plot each candlestick\n",
    "                            for i, (window_idx, row) in enumerate(window_data.iterrows()):\n",
    "                                # Calculate colors based on price movement\n",
    "                                if row['Close'] >= row['Open']:\n",
    "                                    color = 'green'\n",
    "                                    body_height = row['Close'] - row['Open']\n",
    "                                else:\n",
    "                                    color = 'red'\n",
    "                                    body_height = row['Open'] - row['Close']\n",
    "                                \n",
    "                                # Is this candle part of the pattern? (center of the window)\n",
    "                                is_pattern = False\n",
    "                                \n",
    "                                # Single-candle patterns\n",
    "                                if pattern_name in ['doji', 'hammer', 'shooting_star'] and i == 10:\n",
    "                                    is_pattern = True\n",
    "                                # Two-candle patterns\n",
    "                                elif pattern_name == 'engulfing' and i in [9, 10]:\n",
    "                                    is_pattern = True\n",
    "                                # Three-candle patterns\n",
    "                                elif pattern_name in ['morning_star', 'three_white_soldiers'] and i in [8, 9, 10]:\n",
    "                                    is_pattern = True\n",
    "                                \n",
    "                                # Plot the candlestick body\n",
    "                                rect = Rectangle(\n",
    "                                    xy=(i-width/2, min(row['Open'], row['Close'])),\n",
    "                                    width=width,\n",
    "                                    height=body_height,\n",
    "                                    facecolor=color,\n",
    "                                    edgecolor='black' if not is_pattern else 'blue',\n",
    "                                    linewidth=0.5 if not is_pattern else 2.0\n",
    "                                )\n",
    "                                ax.add_patch(rect)\n",
    "                                \n",
    "                                # Plot the upper and lower wicks\n",
    "                                ax.plot([i, i], [row['Low'], min(row['Open'], row['Close'])], \n",
    "                                       color='black' if not is_pattern else 'blue', \n",
    "                                       linewidth=0.5 if not is_pattern else 2.0)\n",
    "                                ax.plot([i, i], [max(row['Open'], row['Close']), row['High']], \n",
    "                                       color='black' if not is_pattern else 'blue', \n",
    "                                       linewidth=0.5 if not is_pattern else 2.0)\n",
    "                            \n",
    "                            # Set y-axis limits with some padding\n",
    "                            y_min = window_data['Low'].min() * 0.95\n",
    "                            y_max = window_data['High'].max() * 1.05\n",
    "                            ax.set_ylim(y_min, y_max)\n",
    "                            \n",
    "                            # Generate a unique filename\n",
    "                            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "                            rand_id = np.random.randint(0, 10000)\n",
    "                            chart_path = os.path.join(\n",
    "                                output_dir, \n",
    "                                pattern_name, \n",
    "                                f\"{ticker}_{pattern_name}_{timestamp}_{rand_id}.jpg\"\n",
    "                            )\n",
    "                            \n",
    "                            # Save the chart as an image\n",
    "                            plt.tight_layout()\n",
    "                            plt.savefig(chart_path)\n",
    "                            plt.close(fig)\n",
    "                            \n",
    "                            # Calculate bounding box coordinates for the pattern\n",
    "                            pattern_x_center = 10  # Default for single-candle patterns\n",
    "                            \n",
    "                            # Depending on pattern type, set different bounding box coordinates\n",
    "                            if pattern_name in ['doji', 'hammer', 'shooting_star']:\n",
    "                                # Single candle patterns\n",
    "                                x_min = pattern_x_center - width/2\n",
    "                                x_max = pattern_x_center + width/2\n",
    "                                \n",
    "                                # Get the specific candle\n",
    "                                candle = window_data.iloc[10]\n",
    "                                \n",
    "                                y_min = min(candle['Open'], candle['Close'])\n",
    "                                y_max = max(candle['Open'], candle['Close'])\n",
    "                                \n",
    "                                # For hammer, include the lower shadow\n",
    "                                if pattern_name == 'hammer':\n",
    "                                    y_min = candle['Low']\n",
    "                                \n",
    "                                # For shooting star, include the upper shadow\n",
    "                                if pattern_name == 'shooting_star':\n",
    "                                    y_max = candle['High']\n",
    "                                \n",
    "                            elif pattern_name == 'engulfing':\n",
    "                                # Two candle pattern (indices 9-10)\n",
    "                                x_min = 9 - width/2\n",
    "                                x_max = 10 + width/2\n",
    "                                \n",
    "                                # First candle\n",
    "                                candle1 = window_data.iloc[9]\n",
    "                                # Second candle\n",
    "                                candle2 = window_data.iloc[10]\n",
    "                                \n",
    "                                y_min = min(candle1['Open'], candle1['Close'], candle2['Open'], candle2['Close'])\n",
    "                                y_max = max(candle1['Open'], candle1['Close'], candle2['Open'], candle2['Close'])\n",
    "                            \n",
    "                            elif pattern_name == 'morning_star':\n",
    "                                # Three candle pattern (indices 8-10)\n",
    "                                x_min = 8 - width/2\n",
    "                                x_max = 10 + width/2\n",
    "                                \n",
    "                                # Get all three candles\n",
    "                                candles = window_data.iloc[8:11]\n",
    "                                \n",
    "                                y_min = min(candles['Low'].min(), candles['Open'].min(), candles['Close'].min())\n",
    "                                y_max = max(candles['High'].max(), candles['Open'].max(), candles['Close'].max())\n",
    "                            \n",
    "                            elif pattern_name == 'three_white_soldiers':\n",
    "                                # Three candle pattern (indices 8-10)\n",
    "                                x_min = 8 - width/2\n",
    "                                x_max = 10 + width/2\n",
    "                                \n",
    "                                # Get all three candles\n",
    "                                candles = window_data.iloc[8:11]\n",
    "                                \n",
    "                                y_min = min(candles['Low'].min(), candles['Open'].min(), candles['Close'].min())\n",
    "                                y_max = max(candles['High'].max(), candles['Open'].max(), candles['Close'].max())\n",
    "                            \n",
    "                            # Normalize coordinates to 0-1 range for YOLO format\n",
    "                            img_width = fig.get_size_inches()[0] * fig.dpi\n",
    "                            img_height = fig.get_size_inches()[1] * fig.dpi\n",
    "                            \n",
    "                            # Convert to YOLO format: [class_id, x_center, y_center, width, height]\n",
    "                            # All values normalized to 0-1\n",
    "                            class_id = list(patterns.keys()).index(pattern_name)\n",
    "                            x_center = (x_min + x_max) / 2 / img_width\n",
    "                            y_center = (y_min + y_max) / 2 / img_height\n",
    "                            width_norm = (x_max - x_min) / img_width\n",
    "                            height_norm = (y_max - y_min) / img_height\n",
    "                            \n",
    "                            # Create YOLO annotation file\n",
    "                            annotation_path = chart_path.replace('.jpg', '.txt')\n",
    "                            with open(annotation_path, 'w') as f:\n",
    "                                f.write(f\"{class_id} {x_center} {y_center} {width_norm} {height_norm}\")\n",
    "                            \n",
    "                            generated_charts.append(chart_path)\n",
    "                            \n",
    "                            # Print out success message\n",
    "                            print(f\"Generated chart for {pattern_name} pattern in {ticker}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing {pattern_name} pattern for {ticker}: {e}\")\n",
    "                    continue\n",
    "                        \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {ticker}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    # Print summary of pattern counts\n",
    "    print(\"\\nPattern detection summary:\")\n",
    "    for pattern_name, count in pattern_counts.items():\n",
    "        print(f\"{pattern_name}: {count}\")\n",
    "    \n",
    "    return generated_charts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7db667",
   "metadata": {},
   "source": [
    "### 2.3 Define pattern detection functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "639131c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_doji(data):\n",
    "    \"\"\"Detect Doji pattern\"\"\"\n",
    "    # A doji has open and close prices that are almost equal\n",
    "    body_size = abs(data['Open'] - data['Close']).values\n",
    "    shadow_size = (data['High'] - data['Low']).values\n",
    "    \n",
    "    # Doji has very small body compared to its shadows\n",
    "    # Using element-wise comparison\n",
    "    doji_pattern = np.zeros(len(data), dtype=bool)\n",
    "    \n",
    "    for i in range(len(data)):\n",
    "        # Avoid division by zero\n",
    "        if shadow_size[i] > 0:\n",
    "            if body_size[i] / shadow_size[i] < 0.1:\n",
    "                doji_pattern[i] = True\n",
    "    \n",
    "    return doji_pattern\n",
    "\n",
    "def detect_hammer(data):\n",
    "    \"\"\"Detect Hammer pattern\"\"\"\n",
    "    hammer_pattern = np.zeros(len(data), dtype=bool)\n",
    "    \n",
    "    for i in range(len(data)):\n",
    "        candle = data.iloc[i]\n",
    "        \n",
    "        # Calculate body size\n",
    "        body_size = abs(candle['Open'] - candle['Close'])\n",
    "        \n",
    "        # Calculate lower and upper shadows\n",
    "        lower_shadow = min(candle['Open'], candle['Close']) - candle['Low']\n",
    "        upper_shadow = candle['High'] - max(candle['Open'], candle['Close'])\n",
    "        \n",
    "        # Hammer criteria:\n",
    "        # 1. Lower shadow at least 2x body\n",
    "        # 2. Upper shadow less than half of body\n",
    "        if lower_shadow > (body_size * 2) and upper_shadow < (body_size * 0.5):\n",
    "            hammer_pattern[i] = True\n",
    "    \n",
    "    return hammer_pattern\n",
    "\n",
    "def detect_shooting_star(data):\n",
    "    \"\"\"Detect Shooting Star pattern\"\"\"\n",
    "    shooting_star_pattern = np.zeros(len(data), dtype=bool)\n",
    "    \n",
    "    for i in range(len(data)):\n",
    "        candle = data.iloc[i]\n",
    "        \n",
    "        # Calculate body size\n",
    "        body_size = abs(candle['Open'] - candle['Close'])\n",
    "        \n",
    "        # Calculate lower and upper shadows\n",
    "        lower_shadow = min(candle['Open'], candle['Close']) - candle['Low']\n",
    "        upper_shadow = candle['High'] - max(candle['Open'], candle['Close'])\n",
    "        \n",
    "        # Shooting star criteria:\n",
    "        # 1. Upper shadow at least 2x body\n",
    "        # 2. Lower shadow less than half of body\n",
    "        if upper_shadow > (body_size * 2) and lower_shadow < (body_size * 0.5):\n",
    "            shooting_star_pattern[i] = True\n",
    "    \n",
    "    return shooting_star_pattern\n",
    "\n",
    "def detect_engulfing(data):\n",
    "    \"\"\"Detect Bullish Engulfing pattern\"\"\"\n",
    "    engulfing_pattern = np.zeros(len(data), dtype=bool)\n",
    "    \n",
    "    for i in range(1, len(data)):\n",
    "        prev_candle = data.iloc[i-1]\n",
    "        curr_candle = data.iloc[i]\n",
    "        \n",
    "        # Previous candle is bearish (red), current is bullish (green)\n",
    "        prev_bearish = prev_candle['Close'] < prev_candle['Open']\n",
    "        curr_bullish = curr_candle['Close'] > curr_candle['Open']\n",
    "        \n",
    "        # Current candle body completely engulfs previous candle body\n",
    "        body_engulfing = (\n",
    "            curr_candle['Open'] < prev_candle['Close'] and\n",
    "            curr_candle['Close'] > prev_candle['Open']\n",
    "        )\n",
    "        \n",
    "        if prev_bearish and curr_bullish and body_engulfing:\n",
    "            engulfing_pattern[i] = True\n",
    "    \n",
    "    return engulfing_pattern\n",
    "\n",
    "def detect_morning_star(data):\n",
    "    \"\"\"Detect Morning Star pattern (three-candle pattern)\"\"\"\n",
    "    morning_star = np.zeros(len(data), dtype=bool)\n",
    "    \n",
    "    for i in range(2, len(data)):\n",
    "        first_candle = data.iloc[i-2]\n",
    "        middle_candle = data.iloc[i-1]\n",
    "        last_candle = data.iloc[i]\n",
    "        \n",
    "        # First candle is bearish (red)\n",
    "        first_bearish = first_candle['Close'] < first_candle['Open']\n",
    "        \n",
    "        # Middle candle is small (doji or small body)\n",
    "        middle_body = abs(middle_candle['Close'] - middle_candle['Open'])\n",
    "        first_body = abs(first_candle['Open'] - first_candle['Close'])\n",
    "        middle_small = middle_body < (first_body * 0.3)\n",
    "        \n",
    "        # Last candle is bullish (green)\n",
    "        last_bullish = last_candle['Close'] > last_candle['Open']\n",
    "        \n",
    "        # Gap down from first to middle\n",
    "        gap_down = middle_candle['High'] < first_candle['Close']\n",
    "        \n",
    "        # Gap up from middle to last\n",
    "        gap_up = last_candle['Low'] > middle_candle['High']\n",
    "        \n",
    "        # Last candle closes above middle point of first candle\n",
    "        first_midpoint = (first_candle['Open'] + first_candle['Close']) / 2\n",
    "        last_closes_high = last_candle['Close'] > first_midpoint\n",
    "        \n",
    "        if (first_bearish and middle_small and last_bullish and \n",
    "            (gap_down or gap_up) and last_closes_high):\n",
    "            morning_star[i] = True\n",
    "    \n",
    "    return morning_star\n",
    "\n",
    "def detect_three_white_soldiers(data):\n",
    "    \"\"\"Detect Three White Soldiers pattern\"\"\"\n",
    "    three_soldiers = np.zeros(len(data), dtype=bool)\n",
    "    \n",
    "    for i in range(2, len(data)):\n",
    "        first = data.iloc[i-2]\n",
    "        second = data.iloc[i-1]\n",
    "        third = data.iloc[i]\n",
    "        \n",
    "        # All three candles are bullish (green)\n",
    "        all_bullish = (\n",
    "            first['Close'] > first['Open'] and\n",
    "            second['Close'] > second['Open'] and\n",
    "            third['Close'] > third['Open']\n",
    "        )\n",
    "        \n",
    "        # Each candle opens within the previous candle's body\n",
    "        progressive_opens = (\n",
    "            second['Open'] > first['Open'] and\n",
    "            second['Open'] < first['Close'] and\n",
    "            third['Open'] > second['Open'] and\n",
    "            third['Open'] < second['Close']\n",
    "        )\n",
    "        \n",
    "        # Each candle closes higher than the previous\n",
    "        progressive_closes = (\n",
    "            second['Close'] > first['Close'] and\n",
    "            third['Close'] > second['Close']\n",
    "        )\n",
    "        \n",
    "        if all_bullish and progressive_opens and progressive_closes:\n",
    "            three_soldiers[i] = True\n",
    "    \n",
    "    return three_soldiers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7110c74d",
   "metadata": {},
   "source": [
    "### 2.4 Create the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85a270d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(output_dir=\"candlestick_dataset\"):\n",
    "    \"\"\"\n",
    "    Create a complete dataset for training YOLOv8\n",
    "    \n",
    "    Args:\n",
    "        output_dir (str): Directory to save the dataset\n",
    "    \"\"\"\n",
    "    # Define stock tickers to use (major indices, tech stocks, etc.)\n",
    "    tickers = [\n",
    "        \"SPY\", \"QQQ\", \"DIA\", \"AAPL\", \"MSFT\", \"GOOGL\", \"AMZN\", \"META\", \"TSLA\", \n",
    "        \"NVDA\", \"AMD\", \"INTC\", \"JPM\", \"V\", \"MA\", \"DIS\", \"NFLX\", \"CSCO\", \"VZ\",\n",
    "        \"T\", \"PFE\", \"MRK\", \"JNJ\", \"PG\", \"KO\", \"PEP\", \"WMT\", \"HD\", \"BA\", \"CAT\"\n",
    "    ]\n",
    "    \n",
    "    # Define patterns to detect\n",
    "    patterns = {\n",
    "        \"doji\": detect_doji,\n",
    "        \"hammer\": detect_hammer,\n",
    "        \"shooting_star\": detect_shooting_star,\n",
    "        \"engulfing\": detect_engulfing,\n",
    "        \"morning_star\": detect_morning_star,\n",
    "        \"three_white_soldiers\": detect_three_white_soldiers\n",
    "    }\n",
    "    \n",
    "    # Generate pattern dataset\n",
    "    print(\"Generating pattern dataset...\")\n",
    "    chart_paths = generate_pattern_dataset(\n",
    "        tickers=tickers,\n",
    "        patterns=patterns,\n",
    "        num_samples_per_pattern=300,  # 300 samples per pattern\n",
    "        output_dir=os.path.join(output_dir, \"raw_data\")\n",
    "    )\n",
    "    \n",
    "    # Check if any charts were generated\n",
    "    if len(chart_paths) == 0:\n",
    "        print(\"No pattern charts were generated. Please check the pattern detection logic.\")\n",
    "        return None\n",
    "    \n",
    "    # Split into train, val, test sets\n",
    "    print(f\"Generated {len(chart_paths)} chart images\")\n",
    "    \n",
    "    # Shuffle paths\n",
    "    random.shuffle(chart_paths)\n",
    "    \n",
    "    # Split: 70% train, 20% val, 10% test\n",
    "    train_split = int(0.7 * len(chart_paths))\n",
    "    val_split = int(0.9 * len(chart_paths))\n",
    "    \n",
    "    train_paths = chart_paths[:train_split]\n",
    "    val_paths = chart_paths[train_split:val_split]\n",
    "    test_paths = chart_paths[val_split:]\n",
    "    \n",
    "    # Create directories\n",
    "    os.makedirs(os.path.join(output_dir, \"train\", \"images\"), exist_ok=True)\n",
    "    os.makedirs(os.path.join(output_dir, \"train\", \"labels\"), exist_ok=True)\n",
    "    os.makedirs(os.path.join(output_dir, \"val\", \"images\"), exist_ok=True)\n",
    "    os.makedirs(os.path.join(output_dir, \"val\", \"labels\"), exist_ok=True)\n",
    "    os.makedirs(os.path.join(output_dir, \"test\", \"images\"), exist_ok=True)\n",
    "    os.makedirs(os.path.join(output_dir, \"test\", \"labels\"), exist_ok=True)\n",
    "    \n",
    "    # Copy files to appropriate directories\n",
    "    def copy_files(paths, dest_type):\n",
    "        for img_path in tqdm(paths, desc=f\"Copying {dest_type} files\"):\n",
    "            # Copy image\n",
    "            img_filename = os.path.basename(img_path)\n",
    "            shutil.copy(\n",
    "                img_path,\n",
    "                os.path.join(output_dir, dest_type, \"images\", img_filename)\n",
    "            )\n",
    "            \n",
    "            # Copy annotation\n",
    "            label_path = img_path.replace(\".jpg\", \".txt\")\n",
    "            label_filename = os.path.basename(label_path)\n",
    "            shutil.copy(\n",
    "                label_path,\n",
    "                os.path.join(output_dir, dest_type, \"labels\", label_filename)\n",
    "            )\n",
    "    \n",
    "    print(\"Organizing dataset...\")\n",
    "    copy_files(train_paths, \"train\")\n",
    "    copy_files(val_paths, \"val\")\n",
    "    copy_files(test_paths, \"test\")\n",
    "    \n",
    "    # Create dataset YAML file\n",
    "    dataset_yaml = {\n",
    "        \"path\": os.path.abspath(output_dir),\n",
    "        \"train\": \"train/images\",\n",
    "        \"val\": \"val/images\",\n",
    "        \"test\": \"test/images\",\n",
    "        \"names\": list(patterns.keys())\n",
    "    }\n",
    "    \n",
    "    with open(os.path.join(output_dir, \"dataset.yaml\"), \"w\") as f:\n",
    "        yaml.dump(dataset_yaml, f)\n",
    "    \n",
    "    print(f\"Dataset created at {output_dir}\")\n",
    "    print(f\"Training set: {len(train_paths)} images\")\n",
    "    print(f\"Validation set: {len(val_paths)} images\")\n",
    "    print(f\"Test set: {len(test_paths)} images\")\n",
    "    \n",
    "    return os.path.join(output_dir, \"dataset.yaml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "494b8377",
   "metadata": {},
   "source": [
    "## 3. Training the YOLOv8 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc108107",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_yolov8_model(dataset_yaml, model_size=\"n\", epochs=100, batch_size=16, image_size=640):\n",
    "    \"\"\"\n",
    "    Train a YOLOv8 model on the candlestick pattern dataset\n",
    "    \n",
    "    Args:\n",
    "        dataset_yaml (str): Path to dataset YAML file\n",
    "        model_size (str): YOLOv8 model size (n, s, m, l, x)\n",
    "        epochs (int): Number of training epochs\n",
    "        batch_size (int): Batch size\n",
    "        image_size (int): Image size\n",
    "        \n",
    "    Returns:\n",
    "        str: Path to the trained model weights\n",
    "    \"\"\"\n",
    "    print(f\"Training YOLOv8{model_size} model on {dataset_yaml}...\")\n",
    "    \n",
    "    # Load a pre-trained YOLOv8 model\n",
    "    model = YOLO(f\"yolov8{model_size}.pt\")\n",
    "    \n",
    "    # Train the model\n",
    "    results = model.train(\n",
    "        data=dataset_yaml,\n",
    "        epochs=epochs,\n",
    "        batch=batch_size,\n",
    "        imgsz=image_size,\n",
    "        patience=20,  # Early stopping patience\n",
    "        save=True,\n",
    "        device=\"0\" if torch.cuda.is_available() else \"cpu\",\n",
    "        verbose=True\n",
    "    )\n",
    "    \n",
    "    # Get path to best model weights\n",
    "    best_weights_path = model.best\n",
    "    \n",
    "    print(f\"Training completed. Best weights saved to: {best_weights_path}\")\n",
    "    \n",
    "    return best_weights_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537534f4",
   "metadata": {},
   "source": [
    "## 4. Fine-tuning the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95d71008",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fine_tune_model(best_weights_path, dataset_yaml, epochs=50, batch_size=8, image_size=640):\n",
    "    \"\"\"\n",
    "    Fine-tune the YOLOv8 model\n",
    "    \n",
    "    Args:\n",
    "        best_weights_path (str): Path to the best weights from initial training\n",
    "        dataset_yaml (str): Path to dataset YAML file\n",
    "        epochs (int): Number of fine-tuning epochs\n",
    "        batch_size (int): Batch size\n",
    "        image_size (int): Image size\n",
    "        \n",
    "    Returns:\n",
    "        str: Path to the fine-tuned model weights\n",
    "    \"\"\"\n",
    "    print(f\"Fine-tuning model {best_weights_path}...\")\n",
    "    \n",
    "    # Load the trained model\n",
    "    model = YOLO(best_weights_path)\n",
    "    \n",
    "    # Fine-tune with a lower learning rate\n",
    "    results = model.train(\n",
    "        data=dataset_yaml,\n",
    "        epochs=epochs,\n",
    "        batch=batch_size,\n",
    "        imgsz=image_size,\n",
    "        patience=20,  # Early stopping patience\n",
    "        save=True,\n",
    "        device=\"0\" if torch.cuda.is_available() else \"cpu\",\n",
    "        verbose=True,\n",
    "        lr0=0.001,  # Lower learning rate for fine-tuning\n",
    "        lrf=0.01,   # Final learning rate as a fraction of initial lr\n",
    "    )\n",
    "    \n",
    "    # Get path to best fine-tuned weights\n",
    "    best_weights_path = model.best\n",
    "    \n",
    "    print(f\"Fine-tuning completed. Best weights saved to: {best_weights_path}\")\n",
    "    \n",
    "    return best_weights_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dac8c73",
   "metadata": {},
   "source": [
    "## 5. Inference for pattern detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e13942ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_patterns(chart_image_path, model_path, conf_threshold=0.25):\n",
    "    \"\"\"\n",
    "    Detect candlestick patterns in a chart image\n",
    "    \n",
    "    Args:\n",
    "        chart_image_path (str): Path to the chart image\n",
    "        model_path (str): Path to the trained YOLOv8 model weights\n",
    "        conf_threshold (float): Confidence threshold for detections\n",
    "        \n",
    "    Returns:\n",
    "        list: List of detected patterns with confidence scores\n",
    "    \"\"\"\n",
    "    # Load the model\n",
    "    model = YOLO(model_path)\n",
    "    \n",
    "    # Run inference\n",
    "    results = model(chart_image_path, conf=conf_threshold)\n",
    "    \n",
    "    # Process results\n",
    "    detections = []\n",
    "    \n",
    "    for result in results:\n",
    "        for i, (box, conf, cls) in enumerate(zip(result.boxes.xyxy, result.boxes.conf, result.boxes.cls)):\n",
    "            x1, y1, x2, y2 = box.tolist()\n",
    "            confidence = conf.item()\n",
    "            class_id = int(cls.item())\n",
    "            class_name = result.names[class_id]\n",
    "            \n",
    "            detections.append({\n",
    "                \"pattern\": class_name,\n",
    "                \"confidence\": confidence,\n",
    "                \"box\": [x1, y1, x2, y2]\n",
    "            })\n",
    "    \n",
    "    return detections\n",
    "\n",
    "def visualize_detections(chart_image_path, detections, output_path=None):\n",
    "    \"\"\"\n",
    "    Visualize detected patterns on a chart image\n",
    "    \n",
    "    Args:\n",
    "        chart_image_path (str): Path to the chart image\n",
    "        detections (list): List of detected patterns\n",
    "        output_path (str, optional): Path to save the output image\n",
    "        \n",
    "    Returns:\n",
    "        numpy.ndarray: Image with visualized detections\n",
    "    \"\"\"\n",
    "    # Load the image\n",
    "    image = cv2.imread(chart_image_path)\n",
    "    \n",
    "    # Convert BGR to RGB\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Colors for different patterns (in RGB)\n",
    "    colors = {\n",
    "        \"doji\": (255, 0, 0),          # Red\n",
    "        \"hammer\": (0, 255, 0),        # Green\n",
    "        \"shooting_star\": (0, 0, 255), # Blue\n",
    "        \"engulfing\": (255, 255, 0),   # Yellow\n",
    "        \"morning_star\": (255, 0, 255),# Magenta\n",
    "        \"three_white_soldiers\": (0, 255, 255) # Cyan\n",
    "    }\n",
    "    \n",
    "    # Draw bounding boxes and labels\n",
    "    for detection in detections:\n",
    "        pattern = detection[\"pattern\"]\n",
    "        conf = detection[\"confidence\"]\n",
    "        box = detection[\"box\"]\n",
    "        \n",
    "        # Get color for this pattern\n",
    "        color = colors.get(pattern, (200, 200, 200))\n",
    "        \n",
    "        # Draw bounding box\n",
    "        cv2.rectangle(\n",
    "            image, \n",
    "            (int(box[0]), int(box[1])), \n",
    "            (int(box[2]), int(box[3])), \n",
    "            color, \n",
    "            2\n",
    "        )\n",
    "        \n",
    "        # Prepare label text\n",
    "        label = f\"{pattern}: {conf:.2f}\"\n",
    "        \n",
    "        # Get text size\n",
    "        text_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 2)[0]\n",
    "        \n",
    "        # Calculate text background rectangle\n",
    "        text_bg_x1 = int(box[0])\n",
    "        text_bg_y1 = int(box[1]) - text_size[1] - 10\n",
    "        text_bg_x2 = int(box[0]) + text_size[0] + 10\n",
    "        text_bg_y2 = int(box[1])\n",
    "        \n",
    "        # Draw text background\n",
    "        cv2.rectangle(\n",
    "            image,\n",
    "            (text_bg_x1, text_bg_y1),\n",
    "            (text_bg_x2, text_bg_y2),\n",
    "            color,\n",
    "            -1\n",
    "        )\n",
    "        \n",
    "        # Draw text\n",
    "        cv2.putText(\n",
    "            image,\n",
    "            label,\n",
    "            (int(box[0] + 5), int(box[1] - 5)),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            0.5,\n",
    "            (255, 255, 255),\n",
    "            2\n",
    "        )\n",
    "    \n",
    "    # Save the output image if requested\n",
    "    if output_path:\n",
    "        # Convert RGB back to BGR for saving\n",
    "        output_img = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        cv2.imwrite(output_path, output_img)\n",
    "    \n",
    "    return image\n",
    "\n",
    "def detect_patterns_from_ticker(ticker, model_path, period=\"1y\", interval=\"1d\", conf_threshold=0.3):\n",
    "    \"\"\"\n",
    "    Generate a chart for a ticker and detect patterns\n",
    "    \n",
    "    Args:\n",
    "        ticker (str): Stock ticker symbol\n",
    "        model_path (str): Path to trained model\n",
    "        period (str): Data period\n",
    "        interval (str): Data interval\n",
    "        conf_threshold (float): Detection confidence threshold\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (chart_path, detections, visualization)\n",
    "    \"\"\"\n",
    "    # Generate chart\n",
    "    chart_path = generate_candlestick_chart(\n",
    "        ticker=ticker,\n",
    "        period=period,\n",
    "        interval=interval,\n",
    "        output_dir=\"inference_charts\"\n",
    "    )\n",
    "    \n",
    "    if chart_path is None:\n",
    "        return None, [], None\n",
    "    \n",
    "    # Detect patterns\n",
    "    detections = detect_patterns(\n",
    "        chart_image_path=chart_path,\n",
    "        model_path=model_path,\n",
    "        conf_threshold=conf_threshold\n",
    "    )\n",
    "    \n",
    "    # Visualize detections\n",
    "    output_path = chart_path.replace(\".jpg\", \"_detected.jpg\")\n",
    "    visualization = visualize_detections(\n",
    "        chart_image_path=chart_path,\n",
    "        detections=detections,\n",
    "        output_path=output_path\n",
    "    )\n",
    "    \n",
    "    return chart_path, detections, visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e421687c",
   "metadata": {},
   "source": [
    "## 6. Main execution flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c7e58ee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating pattern dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing tickers:   0%|          | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YF.download() has changed argument auto_adjust default to True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Processing tickers:   7%|▋         | 2/30 [00:00<00:06,  4.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 1257 days of data for SPY\n",
      "Found 115 doji patterns in SPY\n",
      "Error processing doji pattern for SPY: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error processing hammer pattern for SPY: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error processing shooting_star pattern for SPY: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error processing engulfing pattern for SPY: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error processing morning_star pattern for SPY: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error processing three_white_soldiers pattern for SPY: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Downloaded 1257 days of data for QQQ\n",
      "Found 113 doji patterns in QQQ\n",
      "Error processing doji pattern for QQQ: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error processing hammer pattern for QQQ: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error processing shooting_star pattern for QQQ: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error processing engulfing pattern for QQQ: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error processing morning_star pattern for QQQ: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error processing three_white_soldiers pattern for QQQ: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Processing tickers:  13%|█▎        | 4/30 [00:00<00:04,  5.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 1257 days of data for DIA\n",
      "Found 122 doji patterns in DIA\n",
      "Error processing doji pattern for DIA: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error processing hammer pattern for DIA: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error processing shooting_star pattern for DIA: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error processing engulfing pattern for DIA: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error processing morning_star pattern for DIA: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error processing three_white_soldiers pattern for DIA: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Downloaded 1257 days of data for AAPL\n",
      "Found 132 doji patterns in AAPL\n",
      "Error processing doji pattern for AAPL: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error processing hammer pattern for AAPL: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error processing shooting_star pattern for AAPL: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error processing engulfing pattern for AAPL: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error processing morning_star pattern for AAPL: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error processing three_white_soldiers pattern for AAPL: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Processing tickers:  23%|██▎       | 7/30 [00:01<00:02,  7.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 1257 days of data for MSFT\n",
      "Found 110 doji patterns in MSFT\n",
      "Error processing doji pattern for MSFT: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error processing hammer pattern for MSFT: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error processing shooting_star pattern for MSFT: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error processing engulfing pattern for MSFT: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error processing morning_star pattern for MSFT: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error processing three_white_soldiers pattern for MSFT: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Downloaded 1257 days of data for GOOGL\n",
      "Found 132 doji patterns in GOOGL\n",
      "Error processing doji pattern for GOOGL: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error processing hammer pattern for GOOGL: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error processing shooting_star pattern for GOOGL: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error processing engulfing pattern for GOOGL: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error processing morning_star pattern for GOOGL: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error processing three_white_soldiers pattern for GOOGL: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Downloaded 1257 days of data for AMZN\n",
      "Found 128 doji patterns in AMZN\n",
      "Error processing doji pattern for AMZN: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error processing hammer pattern for AMZN: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error processing shooting_star pattern for AMZN: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error processing engulfing pattern for AMZN: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error processing morning_star pattern for AMZN: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error processing three_white_soldiers pattern for AMZN: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Processing tickers:  33%|███▎      | 10/30 [00:01<00:02,  8.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 1257 days of data for META\n",
      "Found 143 doji patterns in META\n",
      "Error processing doji pattern for META: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error processing hammer pattern for META: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error processing shooting_star pattern for META: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error processing engulfing pattern for META: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error processing morning_star pattern for META: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error processing three_white_soldiers pattern for META: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Downloaded 1257 days of data for TSLA\n",
      "Found 116 doji patterns in TSLA\n",
      "Error processing doji pattern for TSLA: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error processing hammer pattern for TSLA: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error processing shooting_star pattern for TSLA: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error processing engulfing pattern for TSLA: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error processing morning_star pattern for TSLA: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error processing three_white_soldiers pattern for TSLA: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Downloaded 1257 days of data for NVDA\n",
      "Found 128 doji patterns in NVDA\n",
      "Error processing doji pattern for NVDA: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error processing hammer pattern for NVDA: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error processing shooting_star pattern for NVDA: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error processing engulfing pattern for NVDA: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error processing morning_star pattern for NVDA: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error processing three_white_soldiers pattern for NVDA: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Processing tickers:  40%|████      | 12/30 [00:01<00:02,  8.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 1257 days of data for AMD\n",
      "Found 125 doji patterns in AMD\n",
      "Error processing doji pattern for AMD: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error processing hammer pattern for AMD: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error processing shooting_star pattern for AMD: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error processing engulfing pattern for AMD: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error processing morning_star pattern for AMD: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error processing three_white_soldiers pattern for AMD: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Downloaded 1257 days of data for INTC\n",
      "Found 113 doji patterns in INTC\n",
      "Error processing doji pattern for INTC: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error processing hammer pattern for INTC: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error processing shooting_star pattern for INTC: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error processing engulfing pattern for INTC: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error processing morning_star pattern for INTC: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error processing three_white_soldiers pattern for INTC: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Processing tickers:  47%|████▋     | 14/30 [00:01<00:02,  7.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 1257 days of data for JPM\n",
      "Found 152 doji patterns in JPM\n",
      "Error processing doji pattern for JPM: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error processing hammer pattern for JPM: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error processing shooting_star pattern for JPM: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error processing engulfing pattern for JPM: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error processing morning_star pattern for JPM: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error processing three_white_soldiers pattern for JPM: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Downloaded 1257 days of data for V\n",
      "Found 110 doji patterns in V\n",
      "Error processing doji pattern for V: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error processing hammer pattern for V: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error processing shooting_star pattern for V: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error processing engulfing pattern for V: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error processing morning_star pattern for V: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error processing three_white_soldiers pattern for V: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Processing tickers:  53%|█████▎    | 16/30 [00:02<00:01,  7.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 1257 days of data for MA\n",
      "Found 134 doji patterns in MA\n",
      "Error processing doji pattern for MA: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error processing hammer pattern for MA: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error processing shooting_star pattern for MA: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error processing engulfing pattern for MA: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error processing morning_star pattern for MA: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error processing three_white_soldiers pattern for MA: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Downloaded 1257 days of data for DIS\n",
      "Found 120 doji patterns in DIS\n",
      "Error processing doji pattern for DIS: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error processing hammer pattern for DIS: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error processing shooting_star pattern for DIS: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error processing engulfing pattern for DIS: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error processing morning_star pattern for DIS: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error processing three_white_soldiers pattern for DIS: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Processing tickers:  60%|██████    | 18/30 [00:02<00:01,  7.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 1257 days of data for NFLX\n",
      "Found 125 doji patterns in NFLX\n",
      "Error processing doji pattern for NFLX: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error processing hammer pattern for NFLX: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error processing shooting_star pattern for NFLX: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error processing engulfing pattern for NFLX: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error processing morning_star pattern for NFLX: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error processing three_white_soldiers pattern for NFLX: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Downloaded 1257 days of data for CSCO\n",
      "Found 142 doji patterns in CSCO\n",
      "Error processing doji pattern for CSCO: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error processing hammer pattern for CSCO: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error processing shooting_star pattern for CSCO: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error processing engulfing pattern for CSCO: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error processing morning_star pattern for CSCO: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error processing three_white_soldiers pattern for CSCO: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Processing tickers:  67%|██████▋   | 20/30 [00:02<00:01,  7.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 1257 days of data for VZ\n",
      "Found 146 doji patterns in VZ\n",
      "Error processing doji pattern for VZ: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error processing hammer pattern for VZ: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error processing shooting_star pattern for VZ: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error processing engulfing pattern for VZ: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error processing morning_star pattern for VZ: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error processing three_white_soldiers pattern for VZ: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Downloaded 1257 days of data for T\n",
      "Found 129 doji patterns in T\n",
      "Error processing doji pattern for T: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error processing hammer pattern for T: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error processing shooting_star pattern for T: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error processing engulfing pattern for T: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error processing morning_star pattern for T: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error processing three_white_soldiers pattern for T: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Processing tickers:  73%|███████▎  | 22/30 [00:03<00:01,  5.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 1257 days of data for PFE\n",
      "Found 167 doji patterns in PFE\n",
      "Error processing doji pattern for PFE: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error processing hammer pattern for PFE: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error processing shooting_star pattern for PFE: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error processing engulfing pattern for PFE: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error processing morning_star pattern for PFE: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error processing three_white_soldiers pattern for PFE: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Downloaded 1257 days of data for MRK\n",
      "Found 141 doji patterns in MRK\n",
      "Error processing doji pattern for MRK: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error processing hammer pattern for MRK: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error processing shooting_star pattern for MRK: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error processing engulfing pattern for MRK: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error processing morning_star pattern for MRK: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error processing three_white_soldiers pattern for MRK: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "Processing tickers:  77%|███████▋  | 23/30 [00:03<00:01,  5.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 1257 days of data for JNJ\n",
      "Found 138 doji patterns in JNJ\n",
      "Error processing doji pattern for JNJ: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error processing hammer pattern for JNJ: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error processing shooting_star pattern for JNJ: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error processing engulfing pattern for JNJ: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error processing morning_star pattern for JNJ: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error processing three_white_soldiers pattern for JNJ: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 1257 days of data for PG\n",
      "Found 153 doji patterns in PG\n",
      "Error processing doji pattern for PG: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error processing hammer pattern for PG: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error processing shooting_star pattern for PG: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error processing engulfing pattern for PG: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error processing morning_star pattern for PG: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error processing three_white_soldiers pattern for PG: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Processing tickers:  87%|████████▋ | 26/30 [00:04<00:00,  4.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 1257 days of data for KO\n",
      "Found 148 doji patterns in KO\n",
      "Error processing doji pattern for KO: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error processing hammer pattern for KO: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error processing shooting_star pattern for KO: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error processing engulfing pattern for KO: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error processing morning_star pattern for KO: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error processing three_white_soldiers pattern for KO: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Downloaded 1257 days of data for PEP\n",
      "Found 143 doji patterns in PEP\n",
      "Error processing doji pattern for PEP: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error processing hammer pattern for PEP: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error processing shooting_star pattern for PEP: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error processing engulfing pattern for PEP: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error processing morning_star pattern for PEP: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error processing three_white_soldiers pattern for PEP: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Processing tickers:  93%|█████████▎| 28/30 [00:04<00:00,  5.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 1257 days of data for WMT\n",
      "Found 123 doji patterns in WMT\n",
      "Error processing doji pattern for WMT: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error processing hammer pattern for WMT: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error processing shooting_star pattern for WMT: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error processing engulfing pattern for WMT: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error processing morning_star pattern for WMT: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error processing three_white_soldiers pattern for WMT: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Downloaded 1257 days of data for HD\n",
      "Found 121 doji patterns in HD\n",
      "Error processing doji pattern for HD: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error processing hammer pattern for HD: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error processing shooting_star pattern for HD: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error processing engulfing pattern for HD: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error processing morning_star pattern for HD: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error processing three_white_soldiers pattern for HD: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Processing tickers: 100%|██████████| 30/30 [00:04<00:00,  5.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 1257 days of data for BA\n",
      "Found 126 doji patterns in BA\n",
      "Error processing doji pattern for BA: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error processing hammer pattern for BA: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error processing shooting_star pattern for BA: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error processing engulfing pattern for BA: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error processing morning_star pattern for BA: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error processing three_white_soldiers pattern for BA: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Downloaded 1257 days of data for CAT\n",
      "Found 123 doji patterns in CAT\n",
      "Error processing doji pattern for CAT: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error processing hammer pattern for CAT: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error processing shooting_star pattern for CAT: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error processing engulfing pattern for CAT: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error processing morning_star pattern for CAT: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Error processing three_white_soldiers pattern for CAT: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing tickers: 100%|██████████| 30/30 [00:04<00:00,  6.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pattern detection summary:\n",
      "doji: 3918\n",
      "hammer: 0\n",
      "shooting_star: 0\n",
      "engulfing: 0\n",
      "morning_star: 0\n",
      "three_white_soldiers: 0\n",
      "No pattern charts were generated. Please check the pattern detection logic.\n",
      "Dataset creation failed. Please check the pattern detection functions.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1. Create dataset\n",
    "dataset_yaml = create_dataset(output_dir=\"candlestick_dataset\")\n",
    "\n",
    "# Check if dataset was created successfully\n",
    "if dataset_yaml is None:\n",
    "    print(\"Dataset creation failed. Please check the pattern detection functions.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb85b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Train YOLOv8 model\n",
    "best_weights_path = train_yolov8_model(\n",
    "    dataset_yaml=dataset_yaml,\n",
    "    model_size=\"n\",  # Start with a smaller model for faster training\n",
    "    epochs=100,\n",
    "    batch_size=16,\n",
    "    image_size=640\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2917b9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Fine-tune the model\n",
    "fine_tuned_weights = fine_tune_model(\n",
    "    best_weights_path=best_weights_path,\n",
    "    dataset_yaml=dataset_yaml,\n",
    "    epochs=50,\n",
    "    batch_size=8,\n",
    "    image_size=640\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30040e48",
   "metadata": {},
   "outputs": [],
   "source": [
    " # 4. Test inference on new data\n",
    "test_tickers = [\"AAPL\", \"MSFT\", \"GOOGL\", \"AMZN\", \"TSLA\"]\n",
    "\n",
    "print(\"\\nTesting pattern detection on new charts:\")\n",
    "for ticker in test_tickers:\n",
    "    print(f\"\\nAnalyzing {ticker}...\")\n",
    "    chart_path, detections, viz = detect_patterns_from_ticker(\n",
    "        ticker=ticker,\n",
    "        model_path=fine_tuned_weights,\n",
    "        period=\"2y\",\n",
    "        interval=\"1d\",\n",
    "        conf_threshold=0.3\n",
    "    )\n",
    "    \n",
    "    if chart_path is None:\n",
    "        print(f\"Failed to generate chart for {ticker}\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"Chart saved to: {chart_path}\")\n",
    "    \n",
    "    if len(detections) > 0:\n",
    "        print(f\"Detected {len(detections)} patterns:\")\n",
    "        for i, det in enumerate(detections):\n",
    "            print(f\"  {i+1}. {det['pattern']} (confidence: {det['confidence']:.2f})\")\n",
    "    else:\n",
    "        print(\"No patterns detected\")\n",
    "\n",
    "print(\"\\nModel training and testing completed!\")\n",
    "print(f\"Trained model path: {fine_tuned_weights}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
